{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iel3-lQX6bZv"
      },
      "source": [
        "# 2024/11/10 Tutor : GenAI API 使用教學 -- 快速搭建自己的應用\n",
        "\n",
        "#### 在一開始記得先設定好 colab 的雲端副本\n",
        "1. 先點選 檔案 --> 在雲端硬碟中儲存副本\n",
        "2. 等待副本頁面跳出\n",
        "3. 到雲端硬碟上確認是有有存好副本(默認會在雲端硬碟創建一個名為 Colab Noterbooks的資料夾，並在其中新增一個 .ipynb 檔案)，確認後留著雲端硬碟頁面，回到 colab 副本頁面\n",
        "4. 點選右上角的連線，這次不用選 GPU 啥的，因為不需要跑大模型，而是使用 API\n",
        "5. 應該完成了，可以繼續下一步\n",
        "\n",
        "這次下面的介紹都是英文。如果你看不懂英文，自己去看簡報上的中文或是丟ChatGPT，建議不要用google翻譯，google翻譯真的不夠強。\n",
        "但一切真實意思皆以簡報為主。\n",
        "\n",
        "Objective:\n",
        "- Understand how to build your own Language Model Application by calling API and feeding prompts.\n",
        "\n",
        "In this project, you only need to choose **ONE** API.\n",
        "- **Gemini**: Free but slower.\n",
        "- **Other Choices ?**: Coming soon ~~\n",
        "\n",
        "**Start:**\n",
        "Hit one of these two buttons to unfold the blcoks.\n",
        "\n",
        "**Remember**, if you decide to use gemini. You should only execute the code blocks under **\"Gemini API\"**, and no need to execute the code blocks under Other Choices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryzCrCD6Sn5U"
      },
      "source": [
        "# Gemini API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGNPORMFfGei"
      },
      "source": [
        "## Part 0: Install, Import and Setup\n",
        "**Remember to fill in your GOOGLE_API_KEY in this block, the tutorial to get the API is in 2024/11/10 slide ppt.**\n",
        "\n",
        "Please make sure not to share your API with anyone else.\n",
        "\n",
        "取得 Gemini API key "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V9VXIQacd5ZS",
        "outputId": "064146b5-b9d7-4638-8869-49121f6b2d24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.2 (from gradio)\n",
            "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.5.0-py3-none-any.whl (56.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.5 ffmpy-0.4.0 gradio-5.5.0 gradio-client-1.4.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.3 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.2 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n",
            "Set Gemini API sucessfully!!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip3 install gradio\n",
        "!pip install -q -U google-generativeai\n",
        "\n",
        "# Import packages\n",
        "import google.generativeai as genai\n",
        "from typing import List, Tuple\n",
        "import gradio as gr\n",
        "import json\n",
        "\n",
        "# Set up Gemini API key\n",
        "## TODO: Fill in your Gemini API in the \"\"\n",
        "#GOOGLE_API_KEY=\"AIzaSyBovp96uPJRH_cMWpiEzxzaXau8Yi-anYQ\"\n",
        "GOOGLE_API_KEY=\"AIzaSyD1Y3TybVWE14tadPncGJkZKEVkoIne640\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "# Check if you have set your Gemini API successfully\n",
        "# You should see \"Set Gemini API sucessfully!!\" if nothing goes wrong.\n",
        "try:\n",
        "    model.generate_content(\n",
        "      \"test\",\n",
        "    )\n",
        "    print(\"Set Gemini API sucessfully!!\")\n",
        "except:\n",
        "    print(\"There seems to be something wrong with your Gemini API. Please follow our demonstration in the slide to get a correct one.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifCr17v4d12K"
      },
      "source": [
        "## Part 1: Summarization\n",
        "\n",
        "In this task, you are asked to prompt your chatbot into a **summarizer.** Its job is when the user inputs an article, it can summarize the article for the user.\n",
        "\n",
        "You need to:\n",
        "1. Come up with a prompt for summarization and fill it in **prompt_for_summarization**.\n",
        "2. **Hit the run button![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAdCAYAAABfeMd1AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAHBSURBVEhL7ZUviAJREMa/uzMKgkmjRTBaFG1iNwgWk9jMgibhwKRgFgxistjsYhO02C3aNAmahTu+ZfTu7Xv770AOjvvBovvhzLc782Z8KZfLH3gyr/L5VP5NAhHIJBKJWFdQPE9XsVhEJpNBMplEKBSytNvtht1uh81mg8ViYWluOJqk02lUq1XEYjFRzJxOJ0ynU2y3W1F03lKp1Lt8f8CnbzQaCIfDojjD3+RyOVyvV+z3e1FVtJ7wDWq1mtz5hzGMNaGZsER21uu11QMvTLFEMWGZnHrQ7XYxHo9xPp9F0WEsc9hRTHiK3Fgul2g2m5jP56LomHIoJjymXvD4zmYztFotrFYrUb8w5XiYcMjuc+CH4/GI4XCIXq+n9Is57AOrNf4ZPEwul4tVCr/E43FrltrttlIi5mCu7yhv4ueYshyVSgX9fh/5fF7UL0w5FBPuIjcKhQIGgwFKpZIoOqYcigmXHXeRiU6ng3q9jmg0KooOY00LU2s8l52dbDbr63ibYolmwm06mUzkzj+McdrExi3MbXo4HJBIJDw3MUs0Go2Mg3nnd/+0TNwn2T4HXmg9cYPJgxqQQCY/5a+YAJ+sTrD9XPlWtwAAAABJRU5ErkJggg==). (The run button will turn into this state![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAfCAYAAAD0ma06AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAABdaVRYdFNuaXBNZXRhZGF0YQAAAAAAeyJjbGlwUG9pbnRzIjpbeyJ4IjowLCJ5IjowfSx7IngiOjI5LCJ5IjowfSx7IngiOjI5LCJ5IjozMX0seyJ4IjowLCJ5IjozMX1dfRPQE4EAAAOKSURBVEhLvZbnSiRREIVrZsw5i2LAMYCKGQygPwRB//tC+zi+hYKIKAqKoCKKimLOOc/uV95uJ1xnelbwQNO5zq106vpqampC8ovwm/N/w+/3S2pqqgQCAfMkPhJ66PP5JCMjQ/Ly8qSkpEQKCwv1Oj09XT4+PuTl5UVubm7k4OBALi8v5e7uTt7e3szfsYhLyMpLS0ulsrJSysrKpKCgQMnxhoWEQiH1EEAC6e7urpyfn8vp6akuKBrfEmK4urpaOjo6pLi4WI0/PT3J9fW1evL4+Ci5ubnqMd+ygMzMTCU5PDyUtbU12d7eNta+YCVMSUmRzs5O6erqUkNnZ2duyCAkbHjJIggnXtbW1kpjY6Pk5+dLTk6OLC0tyfLycoyXMYT8PDw8LMFgUA2enJzIysqK7O3tSVNTk9TX10t5eblbJO/v73J8fCxbW1uysbEhVVVV6jXfX1xcJCYcGBiQ5uZmJcar+fl5XXF/f7+uPh7wfnZ2VvP4HSLaoqGhQerq6rRYIJuZmVFvRkdHE5IBvhkbG5OWlhbzJBYuYVpamoYxOztbXl9fNelFRUUyODhovvCOoaEhzakNLiGeUHWEklxQ1n19feZt8iA1NmgOqcT29nbp7u6W+/t7zVtWVpauNBwLCwvm6hP8Bygurnt6evTewfT0tKyurpq7T6iHqAY9RO6oyv39fa1GGxYXF92DBXBwDWk0bDaUkMbFI+cnVIMQR8PxyAbbO5uNiKKBkP7CW69i7MDmoWMrHEqIR4TT9lM4Er33AiVE8VEMKpTQopPc/xTYwFY4XMKHhwcldFoDufopbDbcHKJ7NDwFxIE22kDp2w4bbDZcLWUEjYyMqDxNTk7Kzs6OjI+Pe5I0G9DViYkJc/cF18OrqyvtQQqot7dXKioqZG5uzrxNHoi4DS4hCWZgQsx0YPA+Pz+rgCcLFOa7iRH4F7I/5loLBzL2LuxbKB4WwWzjGbmNB8I4NTUlm5ub5kksIgjx8vb2Vic+OWUPQ5sw6ZngGOQdz1iM88/R0ZG+J/d8Ew/WiU9rtLa26oRHgRB0QsReBYNEAiljmkf3WSLEEAKMQcQwbmtrc3uTvQx7GIDqsKmi19bX1607NBsiQhoOQkVvEi4nfISSoUyrkGNCzj05htwLrB5GA0L2peQVzUWQKSDEmXDTPl499EQYDsgh5AwJsohCeUXShD+F2/i/A5G/V6/Q4+FKWs8AAAAASUVORK5CYII=) when sucessfully executed.)** An interface wiill pop up.\n",
        "3. Find an article on your own or use our example article, and fill it in the block named \"Article\".\n",
        "4. Hit the \"Send\" button to produce the summarization. (You can use the \"Temperature\" slide to control the creativeness of the output.)\n",
        "5. If you **want to change your prompt**, hit the run button again to stop the cell. Then go back to step 1.\n",
        "6. After you get the desired result, hit the button \"Export\" to save your result. There will be a file named part1.json appears in the file list. **Remember to download it to your own computer if you need.**\n",
        "\n",
        "Note:\n",
        "\n",
        "*  If you hit the \"Export\" button again, the previous result will be covered, so make sure to download it first.\n",
        "*  prompt example: \"Please summerize the following article in detail and in depth in 500 words, you have to incorporate specific details about the individuals' backgrounds and their daily lives. To enhance the summary, please incorporate direct references to the original text.\"\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Before you run this cell, make sure you have run Part 0 before.\n",
        "\n",
        "**Remember to stop this cell before you go on to the next one.**\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAfCAYAAAD0ma06AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAABdaVRYdFNuaXBNZXRhZGF0YQAAAAAAeyJjbGlwUG9pbnRzIjpbeyJ4IjowLCJ5IjowfSx7IngiOjI5LCJ5IjowfSx7IngiOjI5LCJ5IjozMX0seyJ4IjowLCJ5IjozMX1dfRPQE4EAAAOKSURBVEhLvZbnSiRREIVrZsw5i2LAMYCKGQygPwRB//tC+zi+hYKIKAqKoCKKimLOOc/uV95uJ1xnelbwQNO5zq106vpqampC8ovwm/N/w+/3S2pqqgQCAfMkPhJ66PP5JCMjQ/Ly8qSkpEQKCwv1Oj09XT4+PuTl5UVubm7k4OBALi8v5e7uTt7e3szfsYhLyMpLS0ulsrJSysrKpKCgQMnxhoWEQiH1EEAC6e7urpyfn8vp6akuKBrfEmK4urpaOjo6pLi4WI0/PT3J9fW1evL4+Ci5ubnqMd+ygMzMTCU5PDyUtbU12d7eNta+YCVMSUmRzs5O6erqUkNnZ2duyCAkbHjJIggnXtbW1kpjY6Pk5+dLTk6OLC0tyfLycoyXMYT8PDw8LMFgUA2enJzIysqK7O3tSVNTk9TX10t5eblbJO/v73J8fCxbW1uysbEhVVVV6jXfX1xcJCYcGBiQ5uZmJcar+fl5XXF/f7+uPh7wfnZ2VvP4HSLaoqGhQerq6rRYIJuZmVFvRkdHE5IBvhkbG5OWlhbzJBYuYVpamoYxOztbXl9fNelFRUUyODhovvCOoaEhzakNLiGeUHWEklxQ1n19feZt8iA1NmgOqcT29nbp7u6W+/t7zVtWVpauNBwLCwvm6hP8Bygurnt6evTewfT0tKyurpq7T6iHqAY9RO6oyv39fa1GGxYXF92DBXBwDWk0bDaUkMbFI+cnVIMQR8PxyAbbO5uNiKKBkP7CW69i7MDmoWMrHEqIR4TT9lM4Er33AiVE8VEMKpTQopPc/xTYwFY4XMKHhwcldFoDufopbDbcHKJ7NDwFxIE22kDp2w4bbDZcLWUEjYyMqDxNTk7Kzs6OjI+Pe5I0G9DViYkJc/cF18OrqyvtQQqot7dXKioqZG5uzrxNHoi4DS4hCWZgQsx0YPA+Pz+rgCcLFOa7iRH4F7I/5loLBzL2LuxbKB4WwWzjGbmNB8I4NTUlm5ub5kksIgjx8vb2Vic+OWUPQ5sw6ZngGOQdz1iM88/R0ZG+J/d8Ew/WiU9rtLa26oRHgRB0QsReBYNEAiljmkf3WSLEEAKMQcQwbmtrc3uTvQx7GIDqsKmi19bX1607NBsiQhoOQkVvEi4nfISSoUyrkGNCzj05htwLrB5GA0L2peQVzUWQKSDEmXDTPl499EQYDsgh5AwJsohCeUXShD+F2/i/A5G/V6/Q4+FKWs8AAAAASUVORK5CYII=) means the cell is  running, ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAdCAYAAABfeMd1AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAHBSURBVEhL7ZUviAJREMa/uzMKgkmjRTBaFG1iNwgWk9jMgibhwKRgFgxistjsYhO02C3aNAmahTu+ZfTu7Xv770AOjvvBovvhzLc782Z8KZfLH3gyr/L5VP5NAhHIJBKJWFdQPE9XsVhEJpNBMplEKBSytNvtht1uh81mg8ViYWluOJqk02lUq1XEYjFRzJxOJ0ynU2y3W1F03lKp1Lt8f8CnbzQaCIfDojjD3+RyOVyvV+z3e1FVtJ7wDWq1mtz5hzGMNaGZsER21uu11QMvTLFEMWGZnHrQ7XYxHo9xPp9F0WEsc9hRTHiK3Fgul2g2m5jP56LomHIoJjymXvD4zmYztFotrFYrUb8w5XiYcMjuc+CH4/GI4XCIXq+n9Is57AOrNf4ZPEwul4tVCr/E43FrltrttlIi5mCu7yhv4ueYshyVSgX9fh/5fF7UL0w5FBPuIjcKhQIGgwFKpZIoOqYcigmXHXeRiU6ng3q9jmg0KooOY00LU2s8l52dbDbr63ibYolmwm06mUzkzj+McdrExi3MbXo4HJBIJDw3MUs0Go2Mg3nnd/+0TNwn2T4HXmg9cYPJgxqQQCY/5a+YAJ+sTrD9XPlWtwAAAABJRU5ErkJggg==) means the cell is idle.\n",
        "\n",
        "執行後會出現一個連結，點連結進去後可以輸入一段文字，Gemini將會總結文章並在輸出的最前面和最後面加入五個表情符號。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "LbAzA7K5SuBO",
        "outputId": "40e0c6de-1e80-4724-a348-3dc1c6008c7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:223: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://8e1b3f7cddf0cf9935.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://8e1b3f7cddf0cf9935.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://8e1b3f7cddf0cf9935.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## TODO: Input the prompt in the \"\"\n",
        "prompt_for_summarization = \"總結以下文章並在輸出的最前面和最後面個加上五個表情符號，不可以在其他地方加上表情符號\"\n",
        "# function to clear the conversation\n",
        "def reset() -> List:\n",
        "    return []\n",
        "\n",
        "# function to call the model to generate\n",
        "def interact_summarization(prompt: str, article: str, temp = 1.0) -> List[Tuple[str, str]]:\n",
        "    '''\n",
        "      * Arguments\n",
        "\n",
        "        - prompt: the prompt that we use in this section\n",
        "\n",
        "        - article: the article to be summarized\n",
        "\n",
        "        - temp: the temperature parameter of this model. Temperature is used to control the output of the chatbot.\n",
        "                The higher the temperature is, the more creative response you will get.\n",
        "    '''\n",
        "    input = f\"{prompt}\\n{article}\"\n",
        "    response = model.generate_content(\n",
        "      input,\n",
        "      generation_config=genai.types.GenerationConfig(temperature=temp),\n",
        "      safety_settings=[\n",
        "          {\"category\": \"HARM_CATEGORY_HARASSMENT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          ]\n",
        "    )\n",
        "\n",
        "    return [(input, response.text)]\n",
        "\n",
        "# function to export the whole conversation log\n",
        "def export_summarization(chatbot: List[Tuple[str, str]], article: str) -> None:\n",
        "    '''\n",
        "    * Arguments\n",
        "\n",
        "      - chatbot: the model itself, the conversation is stored in list of tuples\n",
        "\n",
        "      - article: the article to be summarized\n",
        "\n",
        "    '''\n",
        "    target = {\"chatbot\": chatbot, \"article\": article}\n",
        "    with open(\"part1.json\", \"w\") as file:\n",
        "        json.dump(target, file)\n",
        "\n",
        "\n",
        "# This part constructs the Gradio UI interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Part1: Summarization\\nFill in any article you like and let the chatbot summarize it for you!!\")\n",
        "    chatbot = gr.Chatbot()\n",
        "    prompt_textbox = gr.Textbox(label=\"Prompt\", value=prompt_for_summarization, visible=False)\n",
        "    # You can replace the article in variable \"value\" to get the summerization\n",
        "    article_textbox = gr.Textbox(label=\"Article\", interactive = True, value = \"With house prices soaring, it's not easy finding somewhere to live. And this community has thrown in the towel. Meet Seattle's rolling neighborhood of RVs, where each unassuming vehicle is a capsule home. The unusual format has been captured in a series of photographs by visual journalist Anna Erickson. Meet Bud Dodson, 57, and welcome to his home: An RV in Seattle's SoDo where he watches over the parking lot in exchange for a spot . No place like home: John Warden, 52, has turned his $200 vehicle into his home after his apartment burned down years ago . There are around 30 drivers that float in and out of this parking lot in the SoDo (South of Downtown) area of the city in Washington State. One might not notice them in the mornings as hundreds of workers in the nearby factories, such as Starbucks, park up and rush into work. But on the weekends, as the rabble flocks back to their beds, this unique group remains. John Worden, 52, has been living in his vehicle for years since his apartment burned down and he was left homeless. He told Anna his car cost $200, and doesn't drive very well. But for a home, it's just about enough. Though plan on the outside, it is a Pandora's Box inside, Anna tells DailyMail.com. 'It was scattered with trinkets that he had been collecting over the years,' she explained, 'and a pile of beer cans that he was saving to turn in for money.' For work, he panhandles while helping people find parking spaces at Safeco Field stadium, where he used to be a cook. People come and go for work in the factories nearby, but on the weekend it is just the RV-dwellers that area left . Daily life: Here Bud can be seen preparing himself a barbecue on the gravel outside his capsule home, one of about 30 in the community . Eclectic: While Bud's RV is organized and functional, John's is full of trinkets and belongings dating back years . Alongside him - most of the time - is Bud Dodson, 57. While some are forced to move about regularly, Dodson, a maintenance man, looks after the parking lot in exchange for a semi-permanent spot. His home has its own unique stamp on it. 'He had really made the RV his home and taken good care of it,' Anna described. 'It was more functional [than John's] and a cleaner space with a bed, kitchen and bathroom.' Whether organized or eclectic, however, each one is home. 'None of them seem to want to move on,' Anna said. 'It's not perfect but they seem pretty content. Move in, move out: Some have agreements to stay, but others have to keep driving around to find a spot . John works as a panhandler at Safeco Fields stadium, where he used to work as a cook . He is content with his life in between the usual confines of society . Personal: To many this may just seem like a parking lot but for these men it is a very personal space . 'Bud is very grateful, he said the parking lot owner is just such a nice guy to let him live like this.' She came across them when she stopped to ask a seemingly homeless man for directions. 'We got talking,' she said, 'and he mentioned that he lived nearby in an RV. I went round to look and there was a whole bunch of them.' Curious, she spent about two months returning to the spot, meeting with the community and building their trust. 'These RVs are their homes so it's a very personal thing,' she explained.\")\n",
        "    with gr.Column():\n",
        "        gr.Markdown(\"#  Temperature\\n Temperature is used to control the output of the chatbot. The higher the temperature is, the more creative response you will get.\")\n",
        "        temperature_slider = gr.Slider(0.0, 1.0, 0.7, step = 0.1, label=\"Temperature\")\n",
        "    with gr.Row():\n",
        "        sent_button = gr.Button(value=\"Send\")\n",
        "        reset_button = gr.Button(value=\"Reset\")\n",
        "\n",
        "    with gr.Column():\n",
        "        gr.Markdown(\"#  Save your Result.\\n After you get a satisfied result. Click the export button to recode it.\")\n",
        "        export_button = gr.Button(value=\"Export\")\n",
        "    sent_button.click(interact_summarization, inputs=[prompt_textbox, article_textbox, temperature_slider], outputs=[chatbot])\n",
        "    reset_button.click(reset, outputs=[chatbot])\n",
        "    export_button.click(export_summarization, inputs=[chatbot, article_textbox])\n",
        "\n",
        "\n",
        "demo.launch(debug = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdUFavirf5Bj"
      },
      "source": [
        "## Part 2: Role-Play\n",
        "In this task, you are asked to prompt your chatbot into **playing a roleplaying game**. You should assign it a character, then prompt it into that character.\n",
        "\n",
        "You need to:\n",
        "1. Come up with a **character** you want the chatbot to act and the prompt to make the chatbot into that character. Fill the character in **character_for_chatbot**, and fill the prompt in **prompt_for_roleplay**.\n",
        "2. **Hit the run button![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAdCAYAAABfeMd1AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAHBSURBVEhL7ZUviAJREMa/uzMKgkmjRTBaFG1iNwgWk9jMgibhwKRgFgxistjsYhO02C3aNAmahTu+ZfTu7Xv770AOjvvBovvhzLc782Z8KZfLH3gyr/L5VP5NAhHIJBKJWFdQPE9XsVhEJpNBMplEKBSytNvtht1uh81mg8ViYWluOJqk02lUq1XEYjFRzJxOJ0ynU2y3W1F03lKp1Lt8f8CnbzQaCIfDojjD3+RyOVyvV+z3e1FVtJ7wDWq1mtz5hzGMNaGZsER21uu11QMvTLFEMWGZnHrQ7XYxHo9xPp9F0WEsc9hRTHiK3Fgul2g2m5jP56LomHIoJjymXvD4zmYztFotrFYrUb8w5XiYcMjuc+CH4/GI4XCIXq+n9Is57AOrNf4ZPEwul4tVCr/E43FrltrttlIi5mCu7yhv4ueYshyVSgX9fh/5fF7UL0w5FBPuIjcKhQIGgwFKpZIoOqYcigmXHXeRiU6ng3q9jmg0KooOY00LU2s8l52dbDbr63ibYolmwm06mUzkzj+McdrExi3MbXo4HJBIJDw3MUs0Go2Mg3nnd/+0TNwn2T4HXmg9cYPJgxqQQCY/5a+YAJ+sTrD9XPlWtwAAAABJRU5ErkJggg==). (The run button will turn into this state![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAfCAYAAAD0ma06AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAABdaVRYdFNuaXBNZXRhZGF0YQAAAAAAeyJjbGlwUG9pbnRzIjpbeyJ4IjowLCJ5IjowfSx7IngiOjI5LCJ5IjowfSx7IngiOjI5LCJ5IjozMX0seyJ4IjowLCJ5IjozMX1dfRPQE4EAAAOKSURBVEhLvZbnSiRREIVrZsw5i2LAMYCKGQygPwRB//tC+zi+hYKIKAqKoCKKimLOOc/uV95uJ1xnelbwQNO5zq106vpqampC8ovwm/N/w+/3S2pqqgQCAfMkPhJ66PP5JCMjQ/Ly8qSkpEQKCwv1Oj09XT4+PuTl5UVubm7k4OBALi8v5e7uTt7e3szfsYhLyMpLS0ulsrJSysrKpKCgQMnxhoWEQiH1EEAC6e7urpyfn8vp6akuKBrfEmK4urpaOjo6pLi4WI0/PT3J9fW1evL4+Ci5ubnqMd+ygMzMTCU5PDyUtbU12d7eNta+YCVMSUmRzs5O6erqUkNnZ2duyCAkbHjJIggnXtbW1kpjY6Pk5+dLTk6OLC0tyfLycoyXMYT8PDw8LMFgUA2enJzIysqK7O3tSVNTk9TX10t5eblbJO/v73J8fCxbW1uysbEhVVVV6jXfX1xcJCYcGBiQ5uZmJcar+fl5XXF/f7+uPh7wfnZ2VvP4HSLaoqGhQerq6rRYIJuZmVFvRkdHE5IBvhkbG5OWlhbzJBYuYVpamoYxOztbXl9fNelFRUUyODhovvCOoaEhzakNLiGeUHWEklxQ1n19feZt8iA1NmgOqcT29nbp7u6W+/t7zVtWVpauNBwLCwvm6hP8Bygurnt6evTewfT0tKyurpq7T6iHqAY9RO6oyv39fa1GGxYXF92DBXBwDWk0bDaUkMbFI+cnVIMQR8PxyAbbO5uNiKKBkP7CW69i7MDmoWMrHEqIR4TT9lM4Er33AiVE8VEMKpTQopPc/xTYwFY4XMKHhwcldFoDufopbDbcHKJ7NDwFxIE22kDp2w4bbDZcLWUEjYyMqDxNTk7Kzs6OjI+Pe5I0G9DViYkJc/cF18OrqyvtQQqot7dXKioqZG5uzrxNHoi4DS4hCWZgQsx0YPA+Pz+rgCcLFOa7iRH4F7I/5loLBzL2LuxbKB4WwWzjGbmNB8I4NTUlm5ub5kksIgjx8vb2Vic+OWUPQ5sw6ZngGOQdz1iM88/R0ZG+J/d8Ew/WiU9rtLa26oRHgRB0QsReBYNEAiljmkf3WSLEEAKMQcQwbmtrc3uTvQx7GIDqsKmi19bX1607NBsiQhoOQkVvEi4nfISSoUyrkGNCzj05htwLrB5GA0L2peQVzUWQKSDEmXDTPl499EQYDsgh5AwJsohCeUXShD+F2/i/A5G/V6/Q4+FKWs8AAAAASUVORK5CYII=) when sucessfully executed.)** It will pop up an interface.\n",
        "3. Interact with the chatbot for **2 rounds**. Type what you want to say in the block \"Input\", then hit the button \"Send\". (You can use the \"Temperature\" slide to control the creativeness of the output.)\n",
        "4. If you **want to change your prompt or the character**, hit the run button again to stop the cell. Then go back to step 1.\n",
        "5. After you get the desired result, hit the button \"Export\" to save your result. There will be a file named part2.json appears in the file list. **Remember to download it to your own computer if you need.**\n",
        "\n",
        "Note:\n",
        "\n",
        "\n",
        "*  If you hit the \"Export\" button again, the previous result will be covered, so make sure to download it first.\n",
        "*  character example: \"Chinese chatbot\"\n",
        "*  prompt example: \"Tell me what you can do and have a chat with me in Traditional Chinese.\"\n",
        "---\n",
        "\n",
        "\n",
        "Before you run this cell, make sure you have run Part 0.\n",
        "\n",
        "**Remember to stop this cell before you go on to the next one.**\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAfCAYAAAD0ma06AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAABdaVRYdFNuaXBNZXRhZGF0YQAAAAAAeyJjbGlwUG9pbnRzIjpbeyJ4IjowLCJ5IjowfSx7IngiOjI5LCJ5IjowfSx7IngiOjI5LCJ5IjozMX0seyJ4IjowLCJ5IjozMX1dfRPQE4EAAAOKSURBVEhLvZbnSiRREIVrZsw5i2LAMYCKGQygPwRB//tC+zi+hYKIKAqKoCKKimLOOc/uV95uJ1xnelbwQNO5zq106vpqampC8ovwm/N/w+/3S2pqqgQCAfMkPhJ66PP5JCMjQ/Ly8qSkpEQKCwv1Oj09XT4+PuTl5UVubm7k4OBALi8v5e7uTt7e3szfsYhLyMpLS0ulsrJSysrKpKCgQMnxhoWEQiH1EEAC6e7urpyfn8vp6akuKBrfEmK4urpaOjo6pLi4WI0/PT3J9fW1evL4+Ci5ubnqMd+ygMzMTCU5PDyUtbU12d7eNta+YCVMSUmRzs5O6erqUkNnZ2duyCAkbHjJIggnXtbW1kpjY6Pk5+dLTk6OLC0tyfLycoyXMYT8PDw8LMFgUA2enJzIysqK7O3tSVNTk9TX10t5eblbJO/v73J8fCxbW1uysbEhVVVV6jXfX1xcJCYcGBiQ5uZmJcar+fl5XXF/f7+uPh7wfnZ2VvP4HSLaoqGhQerq6rRYIJuZmVFvRkdHE5IBvhkbG5OWlhbzJBYuYVpamoYxOztbXl9fNelFRUUyODhovvCOoaEhzakNLiGeUHWEklxQ1n19feZt8iA1NmgOqcT29nbp7u6W+/t7zVtWVpauNBwLCwvm6hP8Bygurnt6evTewfT0tKyurpq7T6iHqAY9RO6oyv39fa1GGxYXF92DBXBwDWk0bDaUkMbFI+cnVIMQR8PxyAbbO5uNiKKBkP7CW69i7MDmoWMrHEqIR4TT9lM4Er33AiVE8VEMKpTQopPc/xTYwFY4XMKHhwcldFoDufopbDbcHKJ7NDwFxIE22kDp2w4bbDZcLWUEjYyMqDxNTk7Kzs6OjI+Pe5I0G9DViYkJc/cF18OrqyvtQQqot7dXKioqZG5uzrxNHoi4DS4hCWZgQsx0YPA+Pz+rgCcLFOa7iRH4F7I/5loLBzL2LuxbKB4WwWzjGbmNB8I4NTUlm5ub5kksIgjx8vb2Vic+OWUPQ5sw6ZngGOQdz1iM88/R0ZG+J/d8Ew/WiU9rtLa26oRHgRB0QsReBYNEAiljmkf3WSLEEAKMQcQwbmtrc3uTvQx7GIDqsKmi19bX1607NBsiQhoOQkVvEi4nfISSoUyrkGNCzj05htwLrB5GA0L2peQVzUWQKSDEmXDTPl499EQYDsgh5AwJsohCeUXShD+F2/i/A5G/V6/Q4+FKWs8AAAAASUVORK5CYII=) means the cell is  running, ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAdCAYAAABfeMd1AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAHBSURBVEhL7ZUviAJREMa/uzMKgkmjRTBaFG1iNwgWk9jMgibhwKRgFgxistjsYhO02C3aNAmahTu+ZfTu7Xv770AOjvvBovvhzLc782Z8KZfLH3gyr/L5VP5NAhHIJBKJWFdQPE9XsVhEJpNBMplEKBSytNvtht1uh81mg8ViYWluOJqk02lUq1XEYjFRzJxOJ0ynU2y3W1F03lKp1Lt8f8CnbzQaCIfDojjD3+RyOVyvV+z3e1FVtJ7wDWq1mtz5hzGMNaGZsER21uu11QMvTLFEMWGZnHrQ7XYxHo9xPp9F0WEsc9hRTHiK3Fgul2g2m5jP56LomHIoJjymXvD4zmYztFotrFYrUb8w5XiYcMjuc+CH4/GI4XCIXq+n9Is57AOrNf4ZPEwul4tVCr/E43FrltrttlIi5mCu7yhv4ueYshyVSgX9fh/5fF7UL0w5FBPuIjcKhQIGgwFKpZIoOqYcigmXHXeRiU6ng3q9jmg0KooOY00LU2s8l52dbDbr63ibYolmwm06mUzkzj+McdrExi3MbXo4HJBIJDw3MUs0Go2Mg3nnd/+0TNwn2T4HXmg9cYPJgxqQQCY/5a+YAJ+sTrD9XPlWtwAAAABJRU5ErkJggg==) means the cell is idle.\n",
        "\n",
        "這個程式可以讓Gemini角色扮演，第五行可以設定角色，第六行則可以設定條件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "pH_QN45qf4bK",
        "outputId": "99f9ce65-d789-429e-c4eb-d23436bc4891"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:223: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d2e4a2ce88a3>\u001b[0m in \u001b[0;36m<cell line: 84>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mdemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, _frontend)\u001b[0m\n\u001b[1;32m   2607\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2608\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_url\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2609\u001b[0;31m                     share_url = networking.setup_tunnel(\n\u001b[0m\u001b[1;32m   2610\u001b[0m                         \u001b[0mlocal_host\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2611\u001b[0m                         \u001b[0mlocal_port\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_port\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/networking.py\u001b[0m in \u001b[0;36msetup_tunnel\u001b[0;34m(local_host, local_port, share_token, share_server_address)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshare_server_address\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRADIO_API_SERVER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mremote_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremote_port\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"host\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"port\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, headers, cookies, auth, proxy, proxies, follow_redirects, cert, verify, timeout, trust_env)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mon\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mGET\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mrequests\u001b[0m \u001b[0mshould\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude\u001b[0m \u001b[0ma\u001b[0m \u001b[0mrequest\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \"\"\"\n\u001b[0;32m--> 210\u001b[0;31m     return request(\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, params, content, data, files, json, headers, cookies, auth, proxy, proxies, timeout, follow_redirects, verify, cert, trust_env)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[0;32m--> 109\u001b[0;31m     with Client(\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mcookies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mproxy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, auth, params, headers, cookies, verify, cert, http1, http2, proxy, proxies, mounts, timeout, follow_redirects, limits, max_redirects, event_hooks, base_url, transport, app, trust_env, default_encoding)\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0mproxy_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_proxy_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_env_proxies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         self._transport = self._init_transport(\n\u001b[0m\u001b[1;32m    696\u001b[0m             \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0mcert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_init_transport\u001b[0;34m(self, verify, cert, http1, http2, limits, transport, app, trust_env)\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mWSGITransport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         return HTTPTransport(\n\u001b[0m\u001b[1;32m    744\u001b[0m             \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0mcert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, verify, cert, http1, http2, limits, trust_env, proxy, uds, local_address, retries, socket_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0msocket_options\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSOCKET_OPTION\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     ) -> None:\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mssl_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ssl_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mproxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mURL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_config.py\u001b[0m in \u001b[0;36mcreate_ssl_context\u001b[0;34m(cert, verify, trust_env, http2)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mhttp2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m ) -> ssl.SSLContext:\n\u001b[0;32m---> 55\u001b[0;31m     return SSLConfig(\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mcert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhttp2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     ).ssl_context\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_config.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cert, verify, trust_env, http2)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrust_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrust_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssl_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_ssl_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_ssl_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLContext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_config.py\u001b[0m in \u001b[0;36mload_ssl_context\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_ssl_context_verify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_ssl_context_no_verify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_config.py\u001b[0m in \u001b[0;36mload_ssl_context_verify\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mcafile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mca_bundle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"load_verify_locations cafile=%r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcafile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_verify_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcafile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcafile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mca_bundle_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcapath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mca_bundle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# TODO: Fill in the below two lines: character_for_chatbot and prompt_for_roleplay\n",
        "# The first one is the character you want your chatbot to play\n",
        "# The second one is the prompt to make the chatbot be a certain character\n",
        "character_for_chatbot = \"chatbot\"\n",
        "prompt_for_roleplay = \"Tell me what you can do!\"\n",
        "\n",
        "# function to clear the coversation\n",
        "def reset() -> List:\n",
        "    return interact_roleplay([], prompt_for_roleplay)\n",
        "\n",
        "# function to call the model to generate\n",
        "def interact_roleplay(chatbot: List[Tuple[str, str]], user_input: str, temp=1.0) -> List[Tuple[str, str]]:\n",
        "    '''\n",
        "    * Arguments\n",
        "\n",
        "      - user_input: the user input of each round of conversation\n",
        "\n",
        "      - temp: the temperature parameter of this model. Temperature is used to control the output of the chatbot.\n",
        "              The higher the temperature is, the more creative response you will get.\n",
        "\n",
        "    '''\n",
        "    try:\n",
        "        messages = []\n",
        "        for input_text, response_text in chatbot:\n",
        "            messages.append({'role': 'user', 'parts': [input_text]})\n",
        "            messages.append({'role': 'model', 'parts': [response_text]})\n",
        "\n",
        "        messages.append({'role': 'user', 'parts': [user_input]})\n",
        "\n",
        "        response = model.generate_content(\n",
        "          messages,\n",
        "          generation_config=genai.types.GenerationConfig(temperature=temp),\n",
        "          safety_settings=[\n",
        "          {\"category\": \"HARM_CATEGORY_HARASSMENT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          ]\n",
        "        )\n",
        "\n",
        "        chatbot.append((user_input, response.text))\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "        chatbot.append((user_input, f\"Sorry, an error occurred: {e}\"))\n",
        "    return chatbot\n",
        "\n",
        "def export_roleplay(chatbot: List[Tuple[str, str]], description: str) -> None:\n",
        "    '''\n",
        "    * Arguments\n",
        "\n",
        "      - chatbot: the model itself, the conversation is stored in list of tuples\n",
        "\n",
        "      - description: the description of this task\n",
        "\n",
        "    '''\n",
        "    target = {\"chatbot\": chatbot, \"description\": description}\n",
        "    with open(\"part2.json\", \"w\") as file:\n",
        "        json.dump(target, file)\n",
        "\n",
        "first_dialogue = interact_roleplay([], prompt_for_roleplay)\n",
        "\n",
        "# This part constructs the Gradio UI interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(f\"# Part2: Role Play\\nThe chatbot wants to play a role game with you, try interacting with it!!\")\n",
        "    chatbot = gr.Chatbot(value = first_dialogue)\n",
        "    description_textbox = gr.Textbox(label=f\"The character the bot is playing\", interactive = False, value=f\"{character_for_chatbot}\")\n",
        "    input_textbox = gr.Textbox(label=\"Input\", value = \"\")\n",
        "    with gr.Column():\n",
        "        gr.Markdown(\"#  Temperature\\n Temperature is used to control the output of the chatbot. The higher the temperature is, the more creative response you will get.\")\n",
        "        temperature_slider = gr.Slider(0.0, 1.0, 0.7, step = 0.1, label=\"Temperature\")\n",
        "    with gr.Row():\n",
        "        sent_button = gr.Button(value=\"Send\")\n",
        "        reset_button = gr.Button(value=\"Reset\")\n",
        "    with gr.Column():\n",
        "        gr.Markdown(\"#  Save your Result.\\n After you get a satisfied result. Click the export button to recode it.\")\n",
        "        export_button = gr.Button(value=\"Export\")\n",
        "    sent_button.click(interact_roleplay, inputs=[chatbot, input_textbox, temperature_slider], outputs=[chatbot])\n",
        "    reset_button.click(reset, outputs=[chatbot])\n",
        "    export_button.click(export_roleplay, inputs=[chatbot, description_textbox])\n",
        "\n",
        "\n",
        "demo.launch(debug = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOoeAbW4f9XA"
      },
      "source": [
        "## Part 3: Customized Task\n",
        "In this part, you are asked to prompt your chatbot into capable of performing a certain task. You should first come up with a task you want your chatbot to perform, then prompt it into performing that task.\n",
        "\n",
        "You need to:\n",
        "1. Come up with a task and the prompt according to it. Fill the task description in **chatbot_task** and the prompt in **promot_for_task**.\n",
        "2. **Hit the run button![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAdCAYAAABfeMd1AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAHBSURBVEhL7ZUviAJREMa/uzMKgkmjRTBaFG1iNwgWk9jMgibhwKRgFgxistjsYhO02C3aNAmahTu+ZfTu7Xv770AOjvvBovvhzLc782Z8KZfLH3gyr/L5VP5NAhHIJBKJWFdQPE9XsVhEJpNBMplEKBSytNvtht1uh81mg8ViYWluOJqk02lUq1XEYjFRzJxOJ0ynU2y3W1F03lKp1Lt8f8CnbzQaCIfDojjD3+RyOVyvV+z3e1FVtJ7wDWq1mtz5hzGMNaGZsER21uu11QMvTLFEMWGZnHrQ7XYxHo9xPp9F0WEsc9hRTHiK3Fgul2g2m5jP56LomHIoJjymXvD4zmYztFotrFYrUb8w5XiYcMjuc+CH4/GI4XCIXq+n9Is57AOrNf4ZPEwul4tVCr/E43FrltrttlIi5mCu7yhv4ueYshyVSgX9fh/5fF7UL0w5FBPuIjcKhQIGgwFKpZIoOqYcigmXHXeRiU6ng3q9jmg0KooOY00LU2s8l52dbDbr63ibYolmwm06mUzkzj+McdrExi3MbXo4HJBIJDw3MUs0Go2Mg3nnd/+0TNwn2T4HXmg9cYPJgxqQQCY/5a+YAJ+sTrD9XPlWtwAAAABJRU5ErkJggg==). (The run button will turn into this state![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAfCAYAAAD0ma06AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAABdaVRYdFNuaXBNZXRhZGF0YQAAAAAAeyJjbGlwUG9pbnRzIjpbeyJ4IjowLCJ5IjowfSx7IngiOjI5LCJ5IjowfSx7IngiOjI5LCJ5IjozMX0seyJ4IjowLCJ5IjozMX1dfRPQE4EAAAOKSURBVEhLvZbnSiRREIVrZsw5i2LAMYCKGQygPwRB//tC+zi+hYKIKAqKoCKKimLOOc/uV95uJ1xnelbwQNO5zq106vpqampC8ovwm/N/w+/3S2pqqgQCAfMkPhJ66PP5JCMjQ/Ly8qSkpEQKCwv1Oj09XT4+PuTl5UVubm7k4OBALi8v5e7uTt7e3szfsYhLyMpLS0ulsrJSysrKpKCgQMnxhoWEQiH1EEAC6e7urpyfn8vp6akuKBrfEmK4urpaOjo6pLi4WI0/PT3J9fW1evL4+Ci5ubnqMd+ygMzMTCU5PDyUtbU12d7eNta+YCVMSUmRzs5O6erqUkNnZ2duyCAkbHjJIggnXtbW1kpjY6Pk5+dLTk6OLC0tyfLycoyXMYT8PDw8LMFgUA2enJzIysqK7O3tSVNTk9TX10t5eblbJO/v73J8fCxbW1uysbEhVVVV6jXfX1xcJCYcGBiQ5uZmJcar+fl5XXF/f7+uPh7wfnZ2VvP4HSLaoqGhQerq6rRYIJuZmVFvRkdHE5IBvhkbG5OWlhbzJBYuYVpamoYxOztbXl9fNelFRUUyODhovvCOoaEhzakNLiGeUHWEklxQ1n19feZt8iA1NmgOqcT29nbp7u6W+/t7zVtWVpauNBwLCwvm6hP8Bygurnt6evTewfT0tKyurpq7T6iHqAY9RO6oyv39fa1GGxYXF92DBXBwDWk0bDaUkMbFI+cnVIMQR8PxyAbbO5uNiKKBkP7CW69i7MDmoWMrHEqIR4TT9lM4Er33AiVE8VEMKpTQopPc/xTYwFY4XMKHhwcldFoDufopbDbcHKJ7NDwFxIE22kDp2w4bbDZcLWUEjYyMqDxNTk7Kzs6OjI+Pe5I0G9DViYkJc/cF18OrqyvtQQqot7dXKioqZG5uzrxNHoi4DS4hCWZgQsx0YPA+Pz+rgCcLFOa7iRH4F7I/5loLBzL2LuxbKB4WwWzjGbmNB8I4NTUlm5ub5kksIgjx8vb2Vic+OWUPQ5sw6ZngGOQdz1iM88/R0ZG+J/d8Ew/WiU9rtLa26oRHgRB0QsReBYNEAiljmkf3WSLEEAKMQcQwbmtrc3uTvQx7GIDqsKmi19bX1607NBsiQhoOQkVvEi4nfISSoUyrkGNCzj05htwLrB5GA0L2peQVzUWQKSDEmXDTPl499EQYDsgh5AwJsohCeUXShD+F2/i/A5G/V6/Q4+FKWs8AAAAASUVORK5CYII=) when sucessfully executed.)** It will pop up an interface.\n",
        "3. Interact with it for **less than 3 rounds**. Type your input in \"Input\" and hit the button \"Send\". (You can use the \"Temperature\" slide to control the creativeness of the output.)\n",
        "4. If you **want to change your prompt or the task**, hit the run button again to stop the cell. Then go back to step 1.\n",
        "5. After you get the desired result, hit the button \"Export\" to save your result. There will be a file named part3.json appears in the file list. **Remember to download it to your own computer before it disappears.**\n",
        "\n",
        "Note:\n",
        "\n",
        "\n",
        "*  If you hit the \"Export\" button again, the previous result will be covered, so make sure to download it first.\n",
        "*  chatbot task example: \"Tell me the color of the given fruit.\"\n",
        "*  prompt for task: \"Next I will tell you some fruits, and you have to telling me what color they are.\"\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Before you run this cell, make sure you have run both **Install Packages** and **Import and Setup**.\n",
        "\n",
        "**Remember to stop this cell before you go on to the next one.**\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAfCAYAAAD0ma06AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAABdaVRYdFNuaXBNZXRhZGF0YQAAAAAAeyJjbGlwUG9pbnRzIjpbeyJ4IjowLCJ5IjowfSx7IngiOjI5LCJ5IjowfSx7IngiOjI5LCJ5IjozMX0seyJ4IjowLCJ5IjozMX1dfRPQE4EAAAOKSURBVEhLvZbnSiRREIVrZsw5i2LAMYCKGQygPwRB//tC+zi+hYKIKAqKoCKKimLOOc/uV95uJ1xnelbwQNO5zq106vpqampC8ovwm/N/w+/3S2pqqgQCAfMkPhJ66PP5JCMjQ/Ly8qSkpEQKCwv1Oj09XT4+PuTl5UVubm7k4OBALi8v5e7uTt7e3szfsYhLyMpLS0ulsrJSysrKpKCgQMnxhoWEQiH1EEAC6e7urpyfn8vp6akuKBrfEmK4urpaOjo6pLi4WI0/PT3J9fW1evL4+Ci5ubnqMd+ygMzMTCU5PDyUtbU12d7eNta+YCVMSUmRzs5O6erqUkNnZ2duyCAkbHjJIggnXtbW1kpjY6Pk5+dLTk6OLC0tyfLycoyXMYT8PDw8LMFgUA2enJzIysqK7O3tSVNTk9TX10t5eblbJO/v73J8fCxbW1uysbEhVVVV6jXfX1xcJCYcGBiQ5uZmJcar+fl5XXF/f7+uPh7wfnZ2VvP4HSLaoqGhQerq6rRYIJuZmVFvRkdHE5IBvhkbG5OWlhbzJBYuYVpamoYxOztbXl9fNelFRUUyODhovvCOoaEhzakNLiGeUHWEklxQ1n19feZt8iA1NmgOqcT29nbp7u6W+/t7zVtWVpauNBwLCwvm6hP8Bygurnt6evTewfT0tKyurpq7T6iHqAY9RO6oyv39fa1GGxYXF92DBXBwDWk0bDaUkMbFI+cnVIMQR8PxyAbbO5uNiKKBkP7CW69i7MDmoWMrHEqIR4TT9lM4Er33AiVE8VEMKpTQopPc/xTYwFY4XMKHhwcldFoDufopbDbcHKJ7NDwFxIE22kDp2w4bbDZcLWUEjYyMqDxNTk7Kzs6OjI+Pe5I0G9DViYkJc/cF18OrqyvtQQqot7dXKioqZG5uzrxNHoi4DS4hCWZgQsx0YPA+Pz+rgCcLFOa7iRH4F7I/5loLBzL2LuxbKB4WwWzjGbmNB8I4NTUlm5ub5kksIgjx8vb2Vic+OWUPQ5sw6ZngGOQdz1iM88/R0ZG+J/d8Ew/WiU9rtLa26oRHgRB0QsReBYNEAiljmkf3WSLEEAKMQcQwbmtrc3uTvQx7GIDqsKmi19bX1607NBsiQhoOQkVvEi4nfISSoUyrkGNCzj05htwLrB5GA0L2peQVzUWQKSDEmXDTPl499EQYDsgh5AwJsohCeUXShD+F2/i/A5G/V6/Q4+FKWs8AAAAASUVORK5CYII=) means the cell is  running, ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAdCAYAAABfeMd1AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAHBSURBVEhL7ZUviAJREMa/uzMKgkmjRTBaFG1iNwgWk9jMgibhwKRgFgxistjsYhO02C3aNAmahTu+ZfTu7Xv770AOjvvBovvhzLc782Z8KZfLH3gyr/L5VP5NAhHIJBKJWFdQPE9XsVhEJpNBMplEKBSytNvtht1uh81mg8ViYWluOJqk02lUq1XEYjFRzJxOJ0ynU2y3W1F03lKp1Lt8f8CnbzQaCIfDojjD3+RyOVyvV+z3e1FVtJ7wDWq1mtz5hzGMNaGZsER21uu11QMvTLFEMWGZnHrQ7XYxHo9xPp9F0WEsc9hRTHiK3Fgul2g2m5jP56LomHIoJjymXvD4zmYztFotrFYrUb8w5XiYcMjuc+CH4/GI4XCIXq+n9Is57AOrNf4ZPEwul4tVCr/E43FrltrttlIi5mCu7yhv4ueYshyVSgX9fh/5fF7UL0w5FBPuIjcKhQIGgwFKpZIoOqYcigmXHXeRiU6ng3q9jmg0KooOY00LU2s8l52dbDbr63ibYolmwm06mUzkzj+McdrExi3MbXo4HJBIJDw3MUs0Go2Mg3nnd/+0TNwn2T4HXmg9cYPJgxqQQCY/5a+YAJ+sTrD9XPlWtwAAAABJRU5ErkJggg==) means the cell is idle.\n",
        "\n",
        "通過第五六行可以客製化任務"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "uAnsB6NRgLL0",
        "outputId": "601a7b33-b2c4-4107-d9da-598267447c8b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:223: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://a596e12d4ad0196db5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://a596e12d4ad0196db5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TODO: Fill in the below two lines: chatbot_task and chatbot_task\n",
        "# The first is for you to tell the user that the chatbot can perform certain task\n",
        "# The second one is the prompt that make the chatbot able to do certain task\n",
        "chatbot_task = \"你是一個心理諮商師\"\n",
        "prompt_for_task = \"1. 必須是完全繁體中文 2. 最開頭都要附上一個「🧑‍🏫」的表情符號，不能多或少，位置不能錯 3. 每次字數都不能超過 200 字\" # <-\n",
        "\n",
        "# function to clear the conversation\n",
        "def reset() -> List:\n",
        "    return []\n",
        "\n",
        "# function to call the model to generate\n",
        "def interact_customize(chatbot: List[Tuple[str, str]], prompt: str ,user_input: str, temp = 1.0) -> List[Tuple[str, str]]:\n",
        "    '''\n",
        "    * Arguments\n",
        "\n",
        "      - chatbot: the model itself, the conversation is stored in list of tuples\n",
        "\n",
        "      - prompt: the prompt for your desginated task\n",
        "\n",
        "      - user_input: the user input of each round of conversation\n",
        "\n",
        "      - temp: the temperature parameter of this model. Temperature is used to control the output of the chatbot.\n",
        "              The higher the temperature is, the more creative response you will get.\n",
        "\n",
        "    '''\n",
        "    try:\n",
        "        messages = []\n",
        "\n",
        "        for input_text, response_text in chatbot:\n",
        "            messages.append({'role': 'user', 'parts': [input_text]})\n",
        "            messages.append({'role': 'model', 'parts': [response_text]})\n",
        "\n",
        "        messages.append({'role': 'user', 'parts': [prompt+ \"\\n\" + user_input]})\n",
        "\n",
        "        response = model.generate_content(\n",
        "          messages,\n",
        "          generation_config=genai.types.GenerationConfig(temperature=temp),\n",
        "          safety_settings=[\n",
        "          {\"category\": \"HARM_CATEGORY_HARASSMENT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          ]\n",
        "        )\n",
        "\n",
        "        chatbot.append((user_input, response.text))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "        chatbot.append((user_input, f\"Sorry, an error occurred: {e}\"))\n",
        "    return chatbot\n",
        "\n",
        "def export_customized(chatbot: List[Tuple[str, str]], description: str) -> None:\n",
        "    '''\n",
        "    * Arguments\n",
        "\n",
        "      - chatbot: the model itself, the conversation is stored in list of tuples\n",
        "\n",
        "      - description: the description of this task\n",
        "\n",
        "    '''\n",
        "    target = {\"chatbot\": chatbot, \"description\": description}\n",
        "    with open(\"part3.json\", \"w\") as file:\n",
        "        json.dump(target, file)\n",
        "\n",
        "# this part is to construct the Gradio UI interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Part3: Customized task\\nThe chatbot is able to perform a certain task. Try to interact with it!!\")\n",
        "    chatbot = gr.Chatbot()\n",
        "    desc_textbox = gr.Textbox(label=\"Description of the task\", value=chatbot_task, interactive=False)\n",
        "    prompt_textbox = gr.Textbox(label=\"Prompt\", value=prompt_for_task, visible=False)\n",
        "    input_textbox = gr.Textbox(label=\"Input\")\n",
        "    with gr.Column():\n",
        "        gr.Markdown(\"#  Temperature\\n Temperature is used to control the output of the chatbot. The higher the temperature is, the more creative response you will get.\")\n",
        "        temperature_slider = gr.Slider(0.0, 1.0, 0.7, step = 0.1, label=\"Temperature\")\n",
        "    with gr.Row():\n",
        "        sent_button = gr.Button(value=\"Send\")\n",
        "        reset_button = gr.Button(value=\"Reset\")\n",
        "    with gr.Column():\n",
        "        gr.Markdown(\"#  Save your Result.\\n After you get a satisfied result. Click the export button to recode it.\")\n",
        "        export_button = gr.Button(value=\"Export\")\n",
        "    sent_button.click(interact_customize, inputs=[chatbot, prompt_textbox, input_textbox, temperature_slider], outputs=[chatbot])\n",
        "    reset_button.click(reset, outputs=[chatbot])\n",
        "    export_button.click(export_customized, inputs=[chatbot, desc_textbox])\n",
        "\n",
        "demo.launch(debug = True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Xuh2R5DQSrcO"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
